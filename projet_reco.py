# -*- coding: utf-8 -*-
"""projet_reco.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zpZ-hsvh73Ky0sIQa7IH7ddMK7OTGOd2

**Imports**
"""

import glob
import os
import cv2
import random
import matplotlib.pyplot as plt
import numpy as np
import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense
from keras.preprocessing.image import img_to_array
from keras.utils.np_utils import to_categorical
from keras import layers
from keras import models
from keras.models import load_model
from keras.optimizers import Adadelta, Adam
!pip3 install pydub
from pydub import AudioSegment
from scipy import signal
from scipy.io import wavfile
from google.colab import drive
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K
import imageio

drive.mount('/content/drive')

"""**Fonctions de chargement des données (audio -> spectrogramme -> np array)**"""

def sound_to_spec(wavsPath):

	"""
		Découpage des fichiers audios en extraits d'une seconde,
		et création des spectogrammes.

		Entrée:
			wavsPath (list): chemins des fichiers audios

		Sortie: aucune, les extraits découpés et les spectrogrammes sont enregistrés sur le Drive
	"""

	for wavPath in glob.glob(wavsPath):

		# lecture du fichier wav (1 phrase sans silence)
		sound = AudioSegment.from_wav(wavPath)

		# segmentation du son en extraits d'1 seconde
		for i in range(1000, round(len(sound)), 1000):

			# 1 extrait d'une seconde
			my_sound = sound[i-1000:i]
			
			# création du chemin de l'extrait
			file_path_comp = wavPath.split(os.path.sep)
      # file_path_comp[:-3] = chemin jusqu'au dossier ready_data
      # file_path_comp[-2] = le nom du pays
      # file_path_comp[-1].split('.wav')[-2] = le nom du fichier audio long
			file_path = os.path.sep.join(file_path_comp[:-3] + ["ready_data", file_path_comp[-2]] + [(file_path_comp[-1].split('.wav')[-2]+ "_slice"+str(int(i/1000)))])
			
			sound_file = file_path +".wav"
			my_sound.export(sound_file, format="wav")

			# création du spectrogramme pour le morceau d'1 seconde
			image_file = file_path +".png"
			samplingFreq, mySound = wavfile.read(sound_file)
			Pxx, freqs, bins, im = plt.specgram(mySound, NFFT=1028, Fs=samplingFreq)
			plt.ylabel("Frecency [Hz]")
			plt.xlabel("Time [sec]")
			plt.savefig(image_file)

# Variable globale contenant le nombre de fichiers minimum disponible 
# ce nombre varie selon le pays: 2369 (suisse), 2666 (belgique), 3439 (canada), 3779 (france)  
#nb_fichiers = 2369
nb_fichiers = 2666
#nb_fichiers = 3439

def load_data_images(im_paths, width, height, dico_labels):

	"""
		Chargement des images en np array, qu'on donnera en entrée au réseau
		et encodage de leur label.
		
		Entrée:
			im_paths (list): chemins des images à charger
			width (int): largeur de l'image
			height (int): hauteur de l'image
			dico_labels (dict): les labels et leur encoding
		
		Sortie:
			data (list): np arrays des images transformées en représentations numériques
			labels (list):  tous les labels associés aux images 
	"""

	nb_classes = len(dico_labels)
	data = []
	labels = []
	for path in glob.glob(im_paths)[:nb_fichiers]:

		im = cv2.imread(path, 0).astype(np.uint8)
		im = cv2.resize(im, (width, height))
		im = img_to_array(im)
		data.append(im)
		label = path.split(os.path.sep)[-2]
		labels.append(dico_labels[label])
	
	labels = np.array(labels)
	# transforme la liste des labels en une matrice binaire qui les encode
	labels = to_categorical(labels, nb_classes)
	data = np.array(data)
	data = data.reshape(-1, data.shape[1], data.shape[2], 1)
	data = data.astype('float32')
	data /=255.

	return data, labels

"""**Découpage des fichiers audios en extraits d'une seconde et génération des spectrogrammes**"""

# Chemin vers les fichiers wav sans silence
#long_audios_path = "/content/drive/My Drive/reco/no_silence/*/*.wav"

# Découpage des fichiers audios en extraits d'une seconde, et génération des spectrogrammes
#sound_to_spec(long_audios_path)

"""**Chargement des spectrogrammes**"""

"""# Chemins vers les spectros des extraits d'une seconde, suisse INCLUSE
specs_path = ["/content/drive/My Drive/reco/ready_data/belgium/*.png", 
              "/content/drive/My Drive/reco/ready_data/canada/*.png", 
              "/content/drive/My Drive/reco/ready_data/france/*.png", 
              "/content/drive/My Drive/reco/ready_data/switzerland/*.png"]
"""
# Chemins vers les spectros des extraits d'une seconde, suisse EXCLUE (/!\ il faut changer nb_fichiers)
specs_path = ["/content/drive/My Drive/reco/ready_data/belgium/*.png", 
              "/content/drive/My Drive/reco/ready_data/canada/*.png", 
              "/content/drive/My Drive/reco/ready_data/france/*.png"]

# suisse INCLUSE
#dico_labs = {"belgium":0, "canada":1, "france":2, "switzerland":3}

# suisse EXCLUE
dico_labs = {"belgium":0, "canada":1, "france":2}

# Chargement des images et séparation train/test, 80/20
train_data = []
train_labels = []
test_data = []
test_labels = []

len_train = 80*nb_fichiers/100

for path in specs_path:
  print("path:", path)
  p_data, p_labels = load_data_images(path, 28, 28, dico_labs)
  train_data.extend(p_data[:int(len_train)])
  train_labels.extend(p_labels[:int(len_train)])
  test_data.extend(p_data[int(len_train):])
  test_labels.extend(p_labels[int(len_train):])

test_data, test_labels = np.array(test_data), np.array(test_labels)

# shuffle
train = list(zip(train_data, train_labels))
random.shuffle(train)
train_data, train_labels = zip(*train)
train_data, train_labels = np.array(train_data), np.array(train_labels)

"""**Architecture du modèle**"""

def make_cnn(optim, nb_classes):
  
  # cnn basique
  
  model = models.Sequential()
  # couche de convolution 1
  model.add(layers.Conv2D(32,(5,5),activation="relu", input_shape=(28, 28, 1)))
  # couche de pooling 1
  model.add(layers.MaxPooling2D((2, 2)))
  # couche de convolution 2
  model.add(layers.Conv2D(64, (5, 5), activation="relu"))
  # couche de pooling 2
  model.add(layers.MaxPooling2D((2, 2)))
  # transformation de tenseur en vecteur
  model.add(layers.Flatten())
  # couche de perceptron, nb_classes classes en sortie
  model.add(layers.Dense(nb_classes, activation="softmax"))
  # hyperparamètres
  model.compile(loss="categorical_crossentropy", optimizer=optim, metrics = ["accuracy"])
  return model

"""**Entraînement, évaluation et test**"""

# construction du modèle
model = make_cnn("adadelta",len(dico_labs))

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)
mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)

# apprentissage du modèle
model_history = model.fit(train_data, train_labels, 
                        validation_split = 0.2, 
                        batch_size = 40, 
                        epochs = 10, 
                        verbose = 1,
                        callbacks=[es,mc])

# sélection du meilleur modèle
top_model = load_model('best_model.h5')

# calcul de la perte et de l'accuracy sur le test
test_loss, test_acc = top_model.evaluate(test_data, test_labels)
print("\nTest accurracy:", test_acc)

# courbe d'apprentissage
def make_learning_curve(model_history):
  plt.plot(model_history.history['acc'])
  plt.plot(model_history.history['val_acc'])
  plt.title('model accuracy\n(belgium, canada, france)')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  plt.show()

make_learning_curve(model_history)

model.summary()

"""**Visualisation des cartes d'activation**"""

from collections import defaultdict
import pprint as pp

"""
Cette partie a été réalisée à l'aide du lien suivant : https://stackoverflow.com/questions/42315225/viewing-layer-activations-with-keras.
Nous cherchons à obtenir les cartes d'activations du modèle, afin de les sauvergarder sur le Drive.
"""

# liste des couches
outputs = [layer.output for layer in model.layers]
# fonction backend
functor = K.function([model.input] + [K.learning_phase()], outputs)

# dictionnaire: clé = classe, valeur = l'indice d'un exemple du test appartenant à cette classe
dico_classe2ex = defaultdict(int)
# initialisation du dictionnaire avec l'indice du premier exemple pour la première classe: dico_classes2ex["belgium"] = 0
dico_classe2ex[[key for (key, value) in dico_labs.items() if value == list(list(test_labels)[0]).index(1)][0]] = 0

# on parcourt l'ensemble de test, et 
# dès qu'on rencontre un exemple appartenant à une classe qui n'est pas présente dans dico_classe2ex
# on assigne son indice à sa classe dans le dictionnaire
for i in range(len(list(test_data))):

  old_label = [key for (key, value) in dico_labs.items() if value == list(list(test_labels)[0]).index(1)][0]
  current_label = [key for (key, value) in dico_labs.items() if value == list(list(test_labels)[i]).index(1)][0]
  
  if current_label != old_label and current_label not in dico_classe2ex:
  
    dico_classes2ex[current_label] = i
    old_lab = current_label


print("Print dico_classe2ex:")
pp.pprint(dico_classe2ex)


# on parcourt le dictionnaire qui contient un indice d'exemple pour chaque classe
for classe, indice in dico_cartesAct.items():

  # on récupère les sorties des couches, pour l'exemple courant
  layer_out = functor([np.expand_dims(test_data[indice], axis=0), 1.])
  print("\n\nGold =", classe)

  # pour chaque sortie de couche
  for i, x in enumerate(layer_out):

    print("Layer:%s" % outputs[i].name)    
    
    # on essaye de générer son image
    # cela n'est pas possible pour la dernière couche avec cette méthode, d'où le try/catch
    try:
      x = np.rollaxis(x,0,4)
      print ("Final Image Shape: %s\n" % (x.shape,))
      imageio.imwrite('drive/My Drive/reco/activationsimages/activ_%s_layer-%d.png' % (classe, i+1),x[0,:,:])
    except: pass